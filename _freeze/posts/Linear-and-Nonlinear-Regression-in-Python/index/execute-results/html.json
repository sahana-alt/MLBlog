{
  "hash": "81233711644d9df751b87f0d98bfc21f",
  "result": {
    "markdown": "---\ntitle: Linear and Nonlinear Regression in Python\nimage: image.png\nauthor: Swapnil Singh\ndate: '2023-11-06'\ncategories:\n  - regression\n  - supervised learning\nformat:\n  html:\n    code-fold: true\n    code-tools: true\n---\n\nRegression analysis is a powerful statistical method used to understand the relationship between a dependent variable and one or more independent variables. It is widely employed in various fields to make predictions and infer insights from data. In this blog, we'll delve into both linear and nonlinear regression and demonstrate how to implement them in Python.\n\n# Linear Regression\n\nLinear regression is a fundamental technique that models the relationship between two variables by fitting a linear equation to the observed data. The equation takes the form: y = mx + c, where y is the dependent variable, x is the independent variable, m is the slope, and c is the intercept.\n\n## Python Implementation\n\n### Randomly Generated Sampels\n@fig-dummy-results-linear visualizes the linear regression curve on 5 dummy points\n\n::: {.cell execution_count=1}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import LinearRegression\n\n# Generating linear data\nX = np.array([1, 2, 3, 4, 5]).reshape((-1, 1))\ny = np.array([2, 3.9, 6.1, 8.2, 9.8])\n\n# Fitting linear regression model\nmodel = LinearRegression()\nmodel.fit(X, y)\ny_pred = model.predict(X)\n\n# Visualizing linear regression\nplt.scatter(X, y, color='blue', label='Data Points')\nplt.plot(X, y_pred, color='red', label='Linear Regression Line')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.legend()\nplt.show()\n\nslope = model.coef_[0]\nintercept = model.intercept_\n\n# Print the regression equation\nprint(f\"Regression Equation: y = {slope} * X + {intercept}\")\n```\n\n::: {.cell-output .cell-output-display}\n![Linear Regression on Dummy Data](index_files/figure-html/fig-dummy-results-linear-output-1.png){#fig-dummy-results-linear width=585 height=429}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nRegression Equation: y = 1.9900000000000007 * X + 0.029999999999997584\n```\n:::\n:::\n\n\n### COVID-19 Severity Score Dataset\n\n::: {.cell execution_count=2}\n``` {.python .cell-code}\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Load the covid-19 severity dataset\ndata = pd.read_csv('COVID_19_CT_Severity_Score.csv')\nX = data.iloc[:,1:-2]\ny = data.iloc[:,-2]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Create and fit the model\nmodel = LinearRegression()\nmodel.fit(X_train.values, y_train)\n\n# Make predictions\ny_pred = model.predict(X_test.values)\n\nprint('R2 Score: ', metrics.r2_score(y_test, y_pred))\nprint('MSE: ', metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE: ', (metrics.mean_squared_error(y_test, y_pred))**2)\n\ncoefficients = model.coef_\nintercept = model.intercept_\n\n# Print the regression equation\nequation = \"Regression Equation: y = {:.3f}\".format(intercept)\ncols = list(X.columns)\nfor i, coef in enumerate(coefficients):\n    equation += (\" + {:.3f} * \"+cols[i]).format(coef, i)\nprint(equation)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR2 Score:  0.32169205167088033\nMSE:  17.241074996660384\nRMSE:  297.25466704046784\nRegression Equation: y = 2.474 + 0.037 * Age + 0.790 * Gender + 4.576 * GGO + 1.953 * Consolidation + 5.238 * Crazy_paving\n```\n:::\n:::\n\n\n# Nonlinear Regression\n\nNonlinear regression allows us to model complex relationships between variables that cannot be represented by a linear equation. It employs nonlinear functions such as exponentials, logarithms, and polynomials to capture the underlying patterns in the data.\n\n## Python Implementation\n\n### Non Linear Curve Fitting\n@fig-dummy-results-nonlinear visualizes the non linear regression curve on 5 dummy points\n\n::: {.cell execution_count=3}\n``` {.python .cell-code}\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.optimize import curve_fit\n\n# Generating nonlinear data\nX = np.array([1, 2, 3, 4, 5])\ny = np.array([2.5, 3.9, 6.3, 9.2, 14.1])\n\n# Defining a nonlinear function\ndef nonlinear_func(x, a, b, c):\n    return a * np.exp(b * x) + c\n\n# Fitting nonlinear regression model\nparams, covariance = curve_fit(nonlinear_func, X, y)\na, b, c = params\ny_pred = nonlinear_func(X, a, b, c)\n\n# Visualizing nonlinear regression\nplt.scatter(X, y, color='blue', label='Data Points')\nplt.plot(X, y_pred, color='red', label='Nonlinear Regression Curve')\nplt.xlabel('X-axis')\nplt.ylabel('Y-axis')\nplt.legend()\nplt.show()\n```\n\n::: {.cell-output .cell-output-display}\n![Non Linear Regression on Dummy Data](index_files/figure-html/fig-dummy-results-nonlinear-output-1.png){#fig-dummy-results-nonlinear width=585 height=429}\n:::\n:::\n\n\n### Random Forest Regression\n\n::: {.cell execution_count=4}\n``` {.python .cell-code}\nfrom sklearn.ensemble import RandomForestRegressor\nimport numpy as np\nfrom sklearn import datasets\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\n# Load the diabetes dataset\ndata = pd.read_csv('COVID_19_CT_Severity_Score.csv')\nX = data.iloc[:,1:-2]\ny = data.iloc[:,-2]\n\n# Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\n# Fitting the Random Forest Regression model\nregressor = RandomForestRegressor(n_estimators=100, random_state=0)\nregressor.fit(X_train.values, y_train)\n\n# Predicting the values\ny_pred = regressor.predict(X_test.values)\n\nprint('R2 Score: ', metrics.r2_score(y_test, y_pred))\nprint('MSE: ', metrics.mean_squared_error(y_test, y_pred))\nprint('RMSE: ', (metrics.mean_squared_error(y_test, y_pred))**2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nR2 Score:  0.23162348318152914\nMSE:  19.53041709856552\nRMSE:  381.43719204394034\n```\n:::\n:::\n\n\n# Conclusion\nIn this blog, we covered the basics of linear and nonlinear regression, provided Python code examples, and visualized the results with graphs. Linear regression is suitable for modeling simple relationships, while nonlinear regression is essential for capturing complex patterns in the data. Python's rich ecosystem of libraries makes it convenient to implement regression analysis for various datasets and applications.\n\n",
    "supporting": [
      "index_files"
    ],
    "filters": [],
    "includes": {}
  }
}